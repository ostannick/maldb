{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('C:/maldb/python/mlp/')\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ionizer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#METHODS FOR VECTORZING DATA\n",
    "\n",
    "#When we shuffle our training and test arrays, we need to shuffle them in unison so that the indices in the labels array line up with their corresponding peptide in the training array.\n",
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]\n",
    "\n",
    "def aa_to_int(char):\n",
    "    aa_map = {\n",
    "    'A': 0,\n",
    "    'C': 1,\n",
    "    'D': 2,\n",
    "    'E': 3,\n",
    "    'F': 4,\n",
    "    'G': 5,\n",
    "    'H': 6,\n",
    "    'I': 7,\n",
    "    'K': 8,\n",
    "    'L': 9,\n",
    "    'M': 10,\n",
    "    'N': 11,\n",
    "    'P': 12,\n",
    "    'Q': 13,\n",
    "    'R': 14,\n",
    "    'S': 15,\n",
    "    'T': 16,\n",
    "    'V': 17,\n",
    "    'W': 18,\n",
    "    'Y': 19\n",
    "}\n",
    "    \n",
    "    return(aa_map[char])\n",
    "\n",
    "def pad_peptide(arr, max_dim=64):\n",
    "    return np.pad(arr, [(0, max_dim - arr.shape[0]), (0, 0)])\n",
    "\n",
    "def one_hot_padded_sequence(seq):\n",
    "    chars = []\n",
    "    chars[:] = seq\n",
    "    aaints = np.vectorize(aa_to_int)(chars)\n",
    "    one_hot = keras.utils.to_categorical(aaints, num_classes=20)\n",
    "    return pad_peptide(one_hot)\n",
    "    \n",
    "def vectorize_sequences(seqs):\n",
    "    vectorized = []\n",
    "    for seq in seqs:\n",
    "        vectorized.append(one_hot_padded_sequence(seq))\n",
    "    return np.array(vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Get the data from the excel sheet, calculate feature vectors for each entry (row) using ionizers.py\n",
    "train_vecs, train_seqs, train_labels = get_ionizer_training_data('C:/maldb/python/mlp/data/ionizers.csv')\n",
    "\n",
    "#Let's vectorize our sequences\n",
    "x_train = vectorize_sequences(train_seqs)\n",
    "y_train = train_labels.astype('float32')\n",
    "\n",
    "#Shuffle!\n",
    "x_train, y_train = unison_shuffled_copies(x_train, y_train)\n",
    "\n",
    "#Make a test set\n",
    "test_set_size = 50\n",
    "x_test = x_train[:test_set_size]\n",
    "y_test = y_train[:test_set_size]\n",
    "\n",
    "x_train = x_train[test_set_size:]\n",
    "y_train = y_train[test_set_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets build a 1D convolutional model\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "def build_model():\n",
    "\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv1D(20, kernel_size=12, activation=\"relu\", input_shape=(64,20)))\n",
    "    model.add(layers.MaxPooling1D(2))\n",
    "    model.add(layers.Conv1D(20, kernel_size=6, activation=\"relu\"))\n",
    "    model.add(layers.MaxPooling1D(2))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128, activation=\"relu\"))\n",
    "    model.add(layers.Dense(128, activation=\"relu\"))\n",
    "    model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=[\n",
    "            keras.metrics.BinaryAccuracy(),\n",
    "            #keras.metrics.Precision(), \n",
    "            #keras.metrics.Recall()\n",
    "        ],\n",
    "    )\n",
    "    \n",
    "    #model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fold # 0\n",
      "Validation partition =   0 123\n",
      "Training partition 1 =  0 0\n",
      "Training partition 2 =  123 616\n",
      "Epoch 1/1000\n",
      "16/16 [==============================] - 2s 25ms/step - loss: 0.6784 - binary_accuracy: 0.6540 - val_loss: 0.6260 - val_binary_accuracy: 0.6567\n",
      "Epoch 2/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6320 - binary_accuracy: 0.6502 - val_loss: 0.5770 - val_binary_accuracy: 0.6630\n",
      "Epoch 3/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5511 - binary_accuracy: 0.6678 - val_loss: 0.5164 - val_binary_accuracy: 0.6845\n",
      "Epoch 4/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4699 - binary_accuracy: 0.6925 - val_loss: 0.5147 - val_binary_accuracy: 0.7046\n",
      "Epoch 5/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4033 - binary_accuracy: 0.7131 - val_loss: 0.5376 - val_binary_accuracy: 0.7325\n",
      "Epoch 6/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2719 - binary_accuracy: 0.7404 - val_loss: 0.5752 - val_binary_accuracy: 0.7570\n",
      "Epoch 7/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1626 - binary_accuracy: 0.7644 - val_loss: 0.6714 - val_binary_accuracy: 0.7786\n",
      "Epoch 8/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0988 - binary_accuracy: 0.7843 - val_loss: 0.7845 - val_binary_accuracy: 0.7951\n",
      "Epoch 9/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0682 - binary_accuracy: 0.7998 - val_loss: 0.9255 - val_binary_accuracy: 0.8101\n",
      "Epoch 10/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0472 - binary_accuracy: 0.8139 - val_loss: 1.0037 - val_binary_accuracy: 0.8230\n",
      "Epoch 11/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0188 - binary_accuracy: 0.8265 - val_loss: 1.0160 - val_binary_accuracy: 0.8331\n",
      "Epoch 12/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0149 - binary_accuracy: 0.8356 - val_loss: 1.0584 - val_binary_accuracy: 0.8417\n",
      "Epoch 13/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0117 - binary_accuracy: 0.8441 - val_loss: 1.1136 - val_binary_accuracy: 0.8495\n",
      "Epoch 14/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0086 - binary_accuracy: 0.8516 - val_loss: 1.1741 - val_binary_accuracy: 0.8565\n",
      "Epoch 15/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0049 - binary_accuracy: 0.8582 - val_loss: 1.2312 - val_binary_accuracy: 0.8627\n",
      "Epoch 16/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0037 - binary_accuracy: 0.8642 - val_loss: 1.2681 - val_binary_accuracy: 0.8681\n",
      "Epoch 17/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0024 - binary_accuracy: 0.8695 - val_loss: 1.2956 - val_binary_accuracy: 0.8729\n",
      "Epoch 18/1000\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0025 - binary_accuracy: 0.8740 - val_loss: 1.3537 - val_binary_accuracy: 0.8771\n",
      "Epoch 19/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0018 - binary_accuracy: 0.8781 - val_loss: 1.3637 - val_binary_accuracy: 0.8809\n",
      "Epoch 20/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0019 - binary_accuracy: 0.8818 - val_loss: 1.4149 - val_binary_accuracy: 0.8843\n",
      "Epoch 21/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0012 - binary_accuracy: 0.8851 - val_loss: 1.4227 - val_binary_accuracy: 0.8874\n",
      "Epoch 22/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0012 - binary_accuracy: 0.8881 - val_loss: 1.4535 - val_binary_accuracy: 0.8902\n",
      "Epoch 23/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 9.5673e-04 - binary_accuracy: 0.8908 - val_loss: 1.4806 - val_binary_accuracy: 0.8927\n",
      "Epoch 24/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.7644e-04 - binary_accuracy: 0.8933 - val_loss: 1.4945 - val_binary_accuracy: 0.8950\n",
      "Epoch 25/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.1225e-04 - binary_accuracy: 0.8955 - val_loss: 1.5129 - val_binary_accuracy: 0.8972\n",
      "Epoch 26/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.9710e-04 - binary_accuracy: 0.8976 - val_loss: 1.5411 - val_binary_accuracy: 0.8991\n",
      "Epoch 27/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.2704e-04 - binary_accuracy: 0.8995 - val_loss: 1.5483 - val_binary_accuracy: 0.9009\n",
      "Epoch 28/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.5083e-04 - binary_accuracy: 0.9013 - val_loss: 1.5790 - val_binary_accuracy: 0.9026\n",
      "Epoch 29/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 5.4754e-04 - binary_accuracy: 0.9030 - val_loss: 1.5759 - val_binary_accuracy: 0.9042\n",
      "Epoch 30/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.8596e-04 - binary_accuracy: 0.9045 - val_loss: 1.5992 - val_binary_accuracy: 0.9057\n",
      "Epoch 31/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.6356e-04 - binary_accuracy: 0.9059 - val_loss: 1.6054 - val_binary_accuracy: 0.9070\n",
      "Epoch 32/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.3078e-04 - binary_accuracy: 0.9073 - val_loss: 1.6364 - val_binary_accuracy: 0.9083\n",
      "Epoch 33/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.4527e-04 - binary_accuracy: 0.9086 - val_loss: 1.6362 - val_binary_accuracy: 0.9095\n",
      "Epoch 34/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.6443e-04 - binary_accuracy: 0.9097 - val_loss: 1.6513 - val_binary_accuracy: 0.9107\n",
      "Epoch 35/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.3380e-04 - binary_accuracy: 0.9109 - val_loss: 1.6720 - val_binary_accuracy: 0.9117\n",
      "Epoch 36/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.9112e-04 - binary_accuracy: 0.9119 - val_loss: 1.6709 - val_binary_accuracy: 0.9127\n",
      "Epoch 37/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.9833e-04 - binary_accuracy: 0.9129 - val_loss: 1.6863 - val_binary_accuracy: 0.9137\n",
      "Epoch 38/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.5914e-04 - binary_accuracy: 0.9139 - val_loss: 1.6928 - val_binary_accuracy: 0.9146\n",
      "Epoch 39/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.0093e-04 - binary_accuracy: 0.9148 - val_loss: 1.7036 - val_binary_accuracy: 0.9155\n",
      "Epoch 40/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.4660e-04 - binary_accuracy: 0.9156 - val_loss: 1.7162 - val_binary_accuracy: 0.9163\n",
      "Epoch 41/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.2130e-04 - binary_accuracy: 0.9164 - val_loss: 1.7325 - val_binary_accuracy: 0.9171\n",
      "Epoch 42/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.8979e-04 - binary_accuracy: 0.9172 - val_loss: 1.7389 - val_binary_accuracy: 0.9178\n",
      "Epoch 43/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.9889e-04 - binary_accuracy: 0.9179 - val_loss: 1.7451 - val_binary_accuracy: 0.9185\n",
      "Epoch 44/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.2945e-04 - binary_accuracy: 0.9186 - val_loss: 1.7639 - val_binary_accuracy: 0.9192\n",
      "Epoch 45/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.6075e-04 - binary_accuracy: 0.9193 - val_loss: 1.7581 - val_binary_accuracy: 0.9198\n",
      "Epoch 46/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.3452e-04 - binary_accuracy: 0.9199 - val_loss: 1.7663 - val_binary_accuracy: 0.9204\n",
      "Epoch 47/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.3240e-04 - binary_accuracy: 0.9205 - val_loss: 1.7838 - val_binary_accuracy: 0.9210\n",
      "Epoch 48/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.5273e-04 - binary_accuracy: 0.9211 - val_loss: 1.7876 - val_binary_accuracy: 0.9216\n",
      "Epoch 49/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.1372e-04 - binary_accuracy: 0.9217 - val_loss: 1.8007 - val_binary_accuracy: 0.9221\n",
      "Epoch 50/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.1283e-04 - binary_accuracy: 0.9222 - val_loss: 1.8051 - val_binary_accuracy: 0.9226\n",
      "Epoch 51/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.1216e-04 - binary_accuracy: 0.9227 - val_loss: 1.8080 - val_binary_accuracy: 0.9231\n",
      "Epoch 52/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.1531e-04 - binary_accuracy: 0.9232 - val_loss: 1.8208 - val_binary_accuracy: 0.9236\n",
      "Epoch 53/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.1747e-04 - binary_accuracy: 0.9237 - val_loss: 1.8279 - val_binary_accuracy: 0.9241\n",
      "Epoch 54/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 9.1011e-05 - binary_accuracy: 0.9241 - val_loss: 1.8364 - val_binary_accuracy: 0.9245\n",
      "Epoch 55/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 8.8721e-05 - binary_accuracy: 0.9246 - val_loss: 1.8442 - val_binary_accuracy: 0.9250\n",
      "Epoch 56/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.0646e-04 - binary_accuracy: 0.9250 - val_loss: 1.8434 - val_binary_accuracy: 0.9254\n",
      "Epoch 57/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 9.1575e-05 - binary_accuracy: 0.9254 - val_loss: 1.8519 - val_binary_accuracy: 0.9258\n",
      "Epoch 58/1000\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 7.6496e-05 - binary_accuracy: 0.9258 - val_loss: 1.8630 - val_binary_accuracy: 0.9262\n",
      "Epoch 59/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 8.0135e-05 - binary_accuracy: 0.9262 - val_loss: 1.8696 - val_binary_accuracy: 0.9265\n",
      "Epoch 60/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 9.0221e-05 - binary_accuracy: 0.9266 - val_loss: 1.8749 - val_binary_accuracy: 0.9269\n",
      "Epoch 61/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.6573e-05 - binary_accuracy: 0.9269 - val_loss: 1.8772 - val_binary_accuracy: 0.9272\n",
      "Epoch 62/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.1951e-05 - binary_accuracy: 0.9273 - val_loss: 1.8928 - val_binary_accuracy: 0.9276\n",
      "Epoch 63/1000\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 7.8642e-05 - binary_accuracy: 0.9276 - val_loss: 1.8886 - val_binary_accuracy: 0.9279\n",
      "Epoch 64/1000\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 7.1777e-05 - binary_accuracy: 0.9279 - val_loss: 1.9030 - val_binary_accuracy: 0.9282\n",
      "Epoch 65/1000\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 6.0781e-05 - binary_accuracy: 0.9282 - val_loss: 1.9067 - val_binary_accuracy: 0.9285\n",
      "Epoch 66/1000\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 5.3821e-05 - binary_accuracy: 0.9285 - val_loss: 1.9141 - val_binary_accuracy: 0.9288\n",
      "Epoch 67/1000\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 5.0988e-05 - binary_accuracy: 0.9288 - val_loss: 1.9159 - val_binary_accuracy: 0.9291\n",
      "Epoch 68/1000\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 6.7002e-05 - binary_accuracy: 0.9291 - val_loss: 1.9229 - val_binary_accuracy: 0.9294\n",
      "Epoch 69/1000\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 5.6958e-05 - binary_accuracy: 0.9294 - val_loss: 1.9331 - val_binary_accuracy: 0.9296\n",
      "Epoch 70/1000\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 4.9435e-05 - binary_accuracy: 0.9297 - val_loss: 1.9371 - val_binary_accuracy: 0.9299\n",
      "Epoch 71/1000\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 4.3973e-05 - binary_accuracy: 0.9299 - val_loss: 1.9412 - val_binary_accuracy: 0.9302\n",
      "Epoch 72/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 5.1722e-05 - binary_accuracy: 0.9302 - val_loss: 1.9445 - val_binary_accuracy: 0.9304\n",
      "Epoch 73/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 4.7396e-05 - binary_accuracy: 0.9304 - val_loss: 1.9518 - val_binary_accuracy: 0.9307\n",
      "Epoch 74/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 4.6970e-05 - binary_accuracy: 0.9307 - val_loss: 1.9578 - val_binary_accuracy: 0.9309\n",
      "Epoch 75/1000\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 4.2496e-05 - binary_accuracy: 0.9309 - val_loss: 1.9642 - val_binary_accuracy: 0.9311\n",
      "Epoch 76/1000\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 4.8660e-05 - binary_accuracy: 0.9311 - val_loss: 1.9715 - val_binary_accuracy: 0.9313\n",
      "Epoch 77/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 4.7144e-05 - binary_accuracy: 0.9313 - val_loss: 1.9748 - val_binary_accuracy: 0.9316\n",
      "Epoch 78/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 4.9643e-05 - binary_accuracy: 0.9316 - val_loss: 1.9811 - val_binary_accuracy: 0.9318\n",
      "Epoch 79/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 4.0814e-05 - binary_accuracy: 0.9318 - val_loss: 1.9886 - val_binary_accuracy: 0.9320\n",
      "Epoch 80/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.7510e-05 - binary_accuracy: 0.9320 - val_loss: 1.9919 - val_binary_accuracy: 0.9322\n",
      "Epoch 81/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 4.6647e-05 - binary_accuracy: 0.9322 - val_loss: 1.9900 - val_binary_accuracy: 0.9324\n",
      "Epoch 82/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.5037e-05 - binary_accuracy: 0.9324 - val_loss: 1.9995 - val_binary_accuracy: 0.9326\n",
      "Epoch 83/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.6656e-05 - binary_accuracy: 0.9326 - val_loss: 2.0050 - val_binary_accuracy: 0.9328\n",
      "Epoch 84/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.5473e-05 - binary_accuracy: 0.9328 - val_loss: 2.0120 - val_binary_accuracy: 0.9329\n",
      "Epoch 85/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 4.1332e-05 - binary_accuracy: 0.9329 - val_loss: 2.0098 - val_binary_accuracy: 0.9331\n",
      "Epoch 86/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.0252e-05 - binary_accuracy: 0.9331 - val_loss: 2.0177 - val_binary_accuracy: 0.9333\n",
      "Epoch 87/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.5618e-05 - binary_accuracy: 0.9333 - val_loss: 2.0251 - val_binary_accuracy: 0.9335\n",
      "Epoch 88/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.5838e-05 - binary_accuracy: 0.9335 - val_loss: 2.0323 - val_binary_accuracy: 0.9336\n",
      "Epoch 89/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.0443e-05 - binary_accuracy: 0.9336 - val_loss: 2.0368 - val_binary_accuracy: 0.9338\n",
      "Epoch 90/1000\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2.5191e-05 - binary_accuracy: 0.9338 - val_loss: 2.0391 - val_binary_accuracy: 0.9339\n",
      "Epoch 91/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.5563e-05 - binary_accuracy: 0.9339 - val_loss: 2.0445 - val_binary_accuracy: 0.9341\n",
      "Epoch 92/1000\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2.3089e-05 - binary_accuracy: 0.9341 - val_loss: 2.0451 - val_binary_accuracy: 0.9343\n",
      "Epoch 93/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.9111e-05 - binary_accuracy: 0.9342 - val_loss: 2.0507 - val_binary_accuracy: 0.9344\n",
      "Epoch 94/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.2970e-05 - binary_accuracy: 0.9344 - val_loss: 2.0575 - val_binary_accuracy: 0.9345\n",
      "Epoch 95/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.4007e-05 - binary_accuracy: 0.9345 - val_loss: 2.0599 - val_binary_accuracy: 0.9347\n",
      "Epoch 96/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.7213e-05 - binary_accuracy: 0.9347 - val_loss: 2.0671 - val_binary_accuracy: 0.9348\n",
      "Epoch 97/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.4853e-05 - binary_accuracy: 0.9348 - val_loss: 2.0697 - val_binary_accuracy: 0.9350\n",
      "Epoch 98/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.2078e-05 - binary_accuracy: 0.9350 - val_loss: 2.0707 - val_binary_accuracy: 0.9351\n",
      "Epoch 99/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.9224e-05 - binary_accuracy: 0.9351 - val_loss: 2.0744 - val_binary_accuracy: 0.9352\n",
      "Epoch 100/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.3126e-05 - binary_accuracy: 0.9352 - val_loss: 2.0805 - val_binary_accuracy: 0.9354\n",
      "Epoch 101/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.3402e-05 - binary_accuracy: 0.9353 - val_loss: 2.0803 - val_binary_accuracy: 0.9355\n",
      "Epoch 102/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.0751e-05 - binary_accuracy: 0.9355 - val_loss: 2.0892 - val_binary_accuracy: 0.9356\n",
      "Epoch 103/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.4641e-05 - binary_accuracy: 0.9356 - val_loss: 2.0955 - val_binary_accuracy: 0.9357\n",
      "Epoch 104/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.8375e-05 - binary_accuracy: 0.9357 - val_loss: 2.0975 - val_binary_accuracy: 0.9358\n",
      "Epoch 105/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.1075e-05 - binary_accuracy: 0.9358 - val_loss: 2.1021 - val_binary_accuracy: 0.9360\n",
      "Epoch 106/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.2540e-05 - binary_accuracy: 0.9359 - val_loss: 2.1026 - val_binary_accuracy: 0.9361\n",
      "Epoch 107/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.9181e-05 - binary_accuracy: 0.9361 - val_loss: 2.1101 - val_binary_accuracy: 0.9362\n",
      "Epoch 108/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.1809e-05 - binary_accuracy: 0.9362 - val_loss: 2.1124 - val_binary_accuracy: 0.9363\n",
      "Epoch 109/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.7140e-05 - binary_accuracy: 0.9363 - val_loss: 2.1159 - val_binary_accuracy: 0.9364\n",
      "Epoch 110/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.6617e-05 - binary_accuracy: 0.9364 - val_loss: 2.1200 - val_binary_accuracy: 0.9365\n",
      "Epoch 111/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.7550e-05 - binary_accuracy: 0.9365 - val_loss: 2.1243 - val_binary_accuracy: 0.9366\n",
      "Epoch 112/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.4942e-05 - binary_accuracy: 0.9366 - val_loss: 2.1278 - val_binary_accuracy: 0.9367\n",
      "Epoch 113/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.8316e-05 - binary_accuracy: 0.9367 - val_loss: 2.1311 - val_binary_accuracy: 0.9368\n",
      "Epoch 114/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.5749e-05 - binary_accuracy: 0.9368 - val_loss: 2.1369 - val_binary_accuracy: 0.9369\n",
      "Epoch 115/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.5974e-05 - binary_accuracy: 0.9369 - val_loss: 2.1394 - val_binary_accuracy: 0.9370\n",
      "Epoch 116/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.6352e-05 - binary_accuracy: 0.9370 - val_loss: 2.1409 - val_binary_accuracy: 0.9371\n",
      "Epoch 117/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.7161e-05 - binary_accuracy: 0.9371 - val_loss: 2.1449 - val_binary_accuracy: 0.9372\n",
      "Epoch 118/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.4810e-05 - binary_accuracy: 0.9372 - val_loss: 2.1488 - val_binary_accuracy: 0.9373\n",
      "Epoch 119/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.3453e-05 - binary_accuracy: 0.9373 - val_loss: 2.1531 - val_binary_accuracy: 0.9374\n",
      "Epoch 120/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.2245e-05 - binary_accuracy: 0.9374 - val_loss: 2.1560 - val_binary_accuracy: 0.9375\n",
      "Epoch 121/1000\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.6651e-05 - binary_accuracy: 0.9375 - val_loss: 2.1558 - val_binary_accuracy: 0.9376\n",
      "Epoch 122/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.3876e-05 - binary_accuracy: 0.9375 - val_loss: 2.1596 - val_binary_accuracy: 0.9376\n",
      "Epoch 123/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.4328e-05 - binary_accuracy: 0.9376 - val_loss: 2.1684 - val_binary_accuracy: 0.9377\n",
      "Epoch 124/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.2224e-05 - binary_accuracy: 0.9377 - val_loss: 2.1737 - val_binary_accuracy: 0.9378\n",
      "Epoch 125/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.4281e-05 - binary_accuracy: 0.9378 - val_loss: 2.1718 - val_binary_accuracy: 0.9379\n",
      "Epoch 126/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.2213e-05 - binary_accuracy: 0.9379 - val_loss: 2.1742 - val_binary_accuracy: 0.9380\n",
      "Epoch 127/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.1468e-05 - binary_accuracy: 0.9380 - val_loss: 2.1812 - val_binary_accuracy: 0.9381\n",
      "Epoch 128/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.0906e-05 - binary_accuracy: 0.9380 - val_loss: 2.1859 - val_binary_accuracy: 0.9381\n",
      "Epoch 129/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.2836e-05 - binary_accuracy: 0.9381 - val_loss: 2.1868 - val_binary_accuracy: 0.9382\n",
      "Epoch 130/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.4564e-05 - binary_accuracy: 0.9382 - val_loss: 2.1890 - val_binary_accuracy: 0.9383\n",
      "Epoch 131/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.1594e-05 - binary_accuracy: 0.9383 - val_loss: 2.1926 - val_binary_accuracy: 0.9384\n",
      "Epoch 132/1000\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.0130e-05 - binary_accuracy: 0.9383 - val_loss: 2.1975 - val_binary_accuracy: 0.9384\n",
      "Epoch 133/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.0888e-05 - binary_accuracy: 0.9384 - val_loss: 2.1973 - val_binary_accuracy: 0.9385\n",
      "Epoch 134/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.2227e-05 - binary_accuracy: 0.9385 - val_loss: 2.2020 - val_binary_accuracy: 0.9386\n",
      "Epoch 135/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.1068e-05 - binary_accuracy: 0.9386 - val_loss: 2.2055 - val_binary_accuracy: 0.9386\n",
      "Epoch 136/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.0995e-05 - binary_accuracy: 0.9386 - val_loss: 2.2086 - val_binary_accuracy: 0.9387\n",
      "Epoch 137/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.1321e-05 - binary_accuracy: 0.9387 - val_loss: 2.2148 - val_binary_accuracy: 0.9388\n",
      "Epoch 138/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.0038e-05 - binary_accuracy: 0.9388 - val_loss: 2.2177 - val_binary_accuracy: 0.9389\n",
      "Epoch 139/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 9.8634e-06 - binary_accuracy: 0.9388 - val_loss: 2.2214 - val_binary_accuracy: 0.9389\n",
      "Epoch 140/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 8.4707e-06 - binary_accuracy: 0.9389 - val_loss: 2.2233 - val_binary_accuracy: 0.9390\n",
      "Epoch 141/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.1207e-05 - binary_accuracy: 0.9390 - val_loss: 2.2250 - val_binary_accuracy: 0.9390\n",
      "Epoch 142/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 9.8516e-06 - binary_accuracy: 0.9390 - val_loss: 2.2284 - val_binary_accuracy: 0.9391\n",
      "Epoch 143/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 9.4225e-06 - binary_accuracy: 0.9391 - val_loss: 2.2290 - val_binary_accuracy: 0.9392\n",
      "Epoch 144/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.0009e-05 - binary_accuracy: 0.9392 - val_loss: 2.2336 - val_binary_accuracy: 0.9392\n",
      "Epoch 145/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 8.4504e-06 - binary_accuracy: 0.9392 - val_loss: 2.2380 - val_binary_accuracy: 0.9393\n",
      "Epoch 146/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 9.5106e-06 - binary_accuracy: 0.9393 - val_loss: 2.2428 - val_binary_accuracy: 0.9394\n",
      "Epoch 147/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.4394e-06 - binary_accuracy: 0.9393 - val_loss: 2.2430 - val_binary_accuracy: 0.9394\n",
      "Epoch 148/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 9.1397e-06 - binary_accuracy: 0.9394 - val_loss: 2.2449 - val_binary_accuracy: 0.9395\n",
      "Epoch 149/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.9356e-06 - binary_accuracy: 0.9395 - val_loss: 2.2495 - val_binary_accuracy: 0.9395\n",
      "Epoch 150/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.9378e-06 - binary_accuracy: 0.9395 - val_loss: 2.2522 - val_binary_accuracy: 0.9396\n",
      "Epoch 151/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 8.0325e-06 - binary_accuracy: 0.9396 - val_loss: 2.2564 - val_binary_accuracy: 0.9396\n",
      "Epoch 152/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 8.0138e-06 - binary_accuracy: 0.9396 - val_loss: 2.2568 - val_binary_accuracy: 0.9397\n",
      "Epoch 153/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 8.8177e-06 - binary_accuracy: 0.9397 - val_loss: 2.2628 - val_binary_accuracy: 0.9398\n",
      "Epoch 154/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.1930e-06 - binary_accuracy: 0.9397 - val_loss: 2.2661 - val_binary_accuracy: 0.9398\n",
      "Epoch 155/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 8.4248e-06 - binary_accuracy: 0.9398 - val_loss: 2.2693 - val_binary_accuracy: 0.9399\n",
      "Epoch 156/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.8428e-06 - binary_accuracy: 0.9398 - val_loss: 2.2733 - val_binary_accuracy: 0.9399\n",
      "Epoch 157/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.6286e-06 - binary_accuracy: 0.9399 - val_loss: 2.2745 - val_binary_accuracy: 0.9400\n",
      "Epoch 158/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.0156e-06 - binary_accuracy: 0.9400 - val_loss: 2.2781 - val_binary_accuracy: 0.9400\n",
      "Epoch 159/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.3887e-06 - binary_accuracy: 0.9400 - val_loss: 2.2790 - val_binary_accuracy: 0.9401\n",
      "Epoch 160/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.1625e-06 - binary_accuracy: 0.9401 - val_loss: 2.2813 - val_binary_accuracy: 0.9401\n",
      "Epoch 161/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 8.0134e-06 - binary_accuracy: 0.9401 - val_loss: 2.2827 - val_binary_accuracy: 0.9402\n",
      "Epoch 162/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.5398e-06 - binary_accuracy: 0.9402 - val_loss: 2.2877 - val_binary_accuracy: 0.9402\n",
      "Epoch 163/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.0929e-06 - binary_accuracy: 0.9402 - val_loss: 2.2902 - val_binary_accuracy: 0.9403\n",
      "Epoch 164/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.4029e-06 - binary_accuracy: 0.9402 - val_loss: 2.2940 - val_binary_accuracy: 0.9403\n",
      "Epoch 165/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 5.2398e-06 - binary_accuracy: 0.9403 - val_loss: 2.2967 - val_binary_accuracy: 0.9404\n",
      "Epoch 166/1000\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 7.7225e-06 - binary_accuracy: 0.9403 - val_loss: 2.2977 - val_binary_accuracy: 0.9404\n",
      "Epoch 167/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.4416e-06 - binary_accuracy: 0.9404 - val_loss: 2.3006 - val_binary_accuracy: 0.9405\n",
      "Epoch 168/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.2472e-06 - binary_accuracy: 0.9404 - val_loss: 2.3006 - val_binary_accuracy: 0.9405\n",
      "Epoch 169/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 5.9313e-06 - binary_accuracy: 0.9405 - val_loss: 2.3054 - val_binary_accuracy: 0.9405\n",
      "Epoch 170/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 5.1979e-06 - binary_accuracy: 0.9405 - val_loss: 2.3108 - val_binary_accuracy: 0.9406\n",
      "Epoch 171/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 5.9399e-06 - binary_accuracy: 0.9406 - val_loss: 2.3140 - val_binary_accuracy: 0.9406\n",
      "Epoch 172/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 5.7503e-06 - binary_accuracy: 0.9406 - val_loss: 2.3163 - val_binary_accuracy: 0.9407\n",
      "Epoch 173/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.3682e-06 - binary_accuracy: 0.9407 - val_loss: 2.3165 - val_binary_accuracy: 0.9407\n",
      "Epoch 174/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 5.7650e-06 - binary_accuracy: 0.9407 - val_loss: 2.3206 - val_binary_accuracy: 0.9408\n",
      "Epoch 175/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 5.4120e-06 - binary_accuracy: 0.9407 - val_loss: 2.3214 - val_binary_accuracy: 0.9408\n",
      "Epoch 176/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 5.7119e-06 - binary_accuracy: 0.9408 - val_loss: 2.3246 - val_binary_accuracy: 0.9408\n",
      "Epoch 177/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 4.7111e-06 - binary_accuracy: 0.9408 - val_loss: 2.3287 - val_binary_accuracy: 0.9409\n",
      "Epoch 178/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 4.3940e-06 - binary_accuracy: 0.9409 - val_loss: 2.3303 - val_binary_accuracy: 0.9409\n",
      "Epoch 179/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 5.2635e-06 - binary_accuracy: 0.9409 - val_loss: 2.3339 - val_binary_accuracy: 0.9410\n",
      "Epoch 180/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 5.4754e-06 - binary_accuracy: 0.9409 - val_loss: 2.3346 - val_binary_accuracy: 0.9410\n",
      "Epoch 181/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 4.8354e-06 - binary_accuracy: 0.9410 - val_loss: 2.3403 - val_binary_accuracy: 0.9410\n",
      "Epoch 182/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 4.9799e-06 - binary_accuracy: 0.9410 - val_loss: 2.3404 - val_binary_accuracy: 0.9411\n",
      "Epoch 183/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 4.6564e-06 - binary_accuracy: 0.9411 - val_loss: 2.3431 - val_binary_accuracy: 0.9411\n",
      "Epoch 184/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 4.1431e-06 - binary_accuracy: 0.9411 - val_loss: 2.3463 - val_binary_accuracy: 0.9412\n",
      "Epoch 185/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.7434e-06 - binary_accuracy: 0.9411 - val_loss: 2.3483 - val_binary_accuracy: 0.9412\n",
      "Epoch 186/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 4.9187e-06 - binary_accuracy: 0.9412 - val_loss: 2.3516 - val_binary_accuracy: 0.9412\n",
      "Epoch 187/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.9720e-06 - binary_accuracy: 0.9412 - val_loss: 2.3513 - val_binary_accuracy: 0.9413\n",
      "Epoch 188/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 4.5935e-06 - binary_accuracy: 0.9412 - val_loss: 2.3540 - val_binary_accuracy: 0.9413\n",
      "Epoch 189/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 4.9023e-06 - binary_accuracy: 0.9413 - val_loss: 2.3563 - val_binary_accuracy: 0.9413\n",
      "Epoch 190/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 4.6673e-06 - binary_accuracy: 0.9413 - val_loss: 2.3593 - val_binary_accuracy: 0.9414\n",
      "Epoch 191/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 4.9433e-06 - binary_accuracy: 0.9414 - val_loss: 2.3630 - val_binary_accuracy: 0.9414\n",
      "Epoch 192/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 4.0402e-06 - binary_accuracy: 0.9414 - val_loss: 2.3663 - val_binary_accuracy: 0.9414\n",
      "Epoch 193/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.3148e-06 - binary_accuracy: 0.9414 - val_loss: 2.3695 - val_binary_accuracy: 0.9415\n",
      "Epoch 194/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 4.3304e-06 - binary_accuracy: 0.9415 - val_loss: 2.3729 - val_binary_accuracy: 0.9415\n",
      "Epoch 195/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.9655e-06 - binary_accuracy: 0.9415 - val_loss: 2.3768 - val_binary_accuracy: 0.9415\n",
      "Epoch 196/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.6138e-06 - binary_accuracy: 0.9415 - val_loss: 2.3751 - val_binary_accuracy: 0.9416\n",
      "Epoch 197/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 5.4774e-06 - binary_accuracy: 0.9416 - val_loss: 2.3776 - val_binary_accuracy: 0.9416\n",
      "Epoch 198/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.8401e-06 - binary_accuracy: 0.9416 - val_loss: 2.3818 - val_binary_accuracy: 0.9416\n",
      "Epoch 199/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.6394e-06 - binary_accuracy: 0.9416 - val_loss: 2.3857 - val_binary_accuracy: 0.9417\n",
      "Epoch 200/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 4.9104e-06 - binary_accuracy: 0.9417 - val_loss: 2.3864 - val_binary_accuracy: 0.9417\n",
      "Epoch 201/1000\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 4.0384e-06 - binary_accuracy: 0.9417 - val_loss: 2.3896 - val_binary_accuracy: 0.9417\n",
      "Epoch 202/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.9972e-06 - binary_accuracy: 0.9417 - val_loss: 2.3905 - val_binary_accuracy: 0.9418\n",
      "Epoch 203/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.6307e-06 - binary_accuracy: 0.9418 - val_loss: 2.3916 - val_binary_accuracy: 0.9418\n",
      "Epoch 204/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.7871e-06 - binary_accuracy: 0.9418 - val_loss: 2.3940 - val_binary_accuracy: 0.9418\n",
      "Epoch 205/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.0733e-06 - binary_accuracy: 0.9418 - val_loss: 2.3959 - val_binary_accuracy: 0.9419\n",
      "Epoch 206/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.5956e-06 - binary_accuracy: 0.9418 - val_loss: 2.3982 - val_binary_accuracy: 0.9419\n",
      "Epoch 207/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.3205e-06 - binary_accuracy: 0.9419 - val_loss: 2.4022 - val_binary_accuracy: 0.9419\n",
      "Epoch 208/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.5298e-06 - binary_accuracy: 0.9419 - val_loss: 2.4048 - val_binary_accuracy: 0.9420\n",
      "Epoch 209/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.7015e-06 - binary_accuracy: 0.9419 - val_loss: 2.4083 - val_binary_accuracy: 0.9420\n",
      "Epoch 210/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.3424e-06 - binary_accuracy: 0.9420 - val_loss: 2.4097 - val_binary_accuracy: 0.9420\n",
      "Epoch 211/1000\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 3.1307e-06 - binary_accuracy: 0.9420 - val_loss: 2.4134 - val_binary_accuracy: 0.9420\n",
      "Epoch 212/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.7224e-06 - binary_accuracy: 0.9420 - val_loss: 2.4126 - val_binary_accuracy: 0.9421\n",
      "Epoch 213/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.3655e-06 - binary_accuracy: 0.9421 - val_loss: 2.4159 - val_binary_accuracy: 0.9421\n",
      "Epoch 214/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.0531e-06 - binary_accuracy: 0.9421 - val_loss: 2.4182 - val_binary_accuracy: 0.9421\n",
      "Epoch 215/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.5484e-06 - binary_accuracy: 0.9421 - val_loss: 2.4202 - val_binary_accuracy: 0.9421\n",
      "Epoch 216/1000\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2.4599e-06 - binary_accuracy: 0.9421 - val_loss: 2.4256 - val_binary_accuracy: 0.9422\n",
      "Epoch 217/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.3438e-06 - binary_accuracy: 0.9422 - val_loss: 2.4266 - val_binary_accuracy: 0.9422\n",
      "Epoch 218/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.3371e-06 - binary_accuracy: 0.9422 - val_loss: 2.4286 - val_binary_accuracy: 0.9422\n",
      "Epoch 219/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.0008e-06 - binary_accuracy: 0.9422 - val_loss: 2.4300 - val_binary_accuracy: 0.9423\n",
      "Epoch 220/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.5311e-06 - binary_accuracy: 0.9422 - val_loss: 2.4329 - val_binary_accuracy: 0.9423\n",
      "Epoch 221/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.1104e-06 - binary_accuracy: 0.9423 - val_loss: 2.4353 - val_binary_accuracy: 0.9423\n",
      "Epoch 222/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.4838e-06 - binary_accuracy: 0.9423 - val_loss: 2.4385 - val_binary_accuracy: 0.9423\n",
      "Epoch 223/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.2954e-06 - binary_accuracy: 0.9423 - val_loss: 2.4421 - val_binary_accuracy: 0.9424\n",
      "Epoch 224/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.5866e-06 - binary_accuracy: 0.9423 - val_loss: 2.4436 - val_binary_accuracy: 0.9424\n",
      "Epoch 225/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.8343e-06 - binary_accuracy: 0.9424 - val_loss: 2.4439 - val_binary_accuracy: 0.9424\n",
      "Epoch 226/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.8509e-06 - binary_accuracy: 0.9424 - val_loss: 2.4463 - val_binary_accuracy: 0.9424\n",
      "Epoch 227/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.8706e-06 - binary_accuracy: 0.9424 - val_loss: 2.4524 - val_binary_accuracy: 0.9425\n",
      "Epoch 228/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.3894e-06 - binary_accuracy: 0.9424 - val_loss: 2.4542 - val_binary_accuracy: 0.9425\n",
      "Epoch 229/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.9070e-06 - binary_accuracy: 0.9425 - val_loss: 2.4541 - val_binary_accuracy: 0.9425\n",
      "Epoch 230/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.8854e-06 - binary_accuracy: 0.9425 - val_loss: 2.4574 - val_binary_accuracy: 0.9425\n",
      "Epoch 231/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.0694e-06 - binary_accuracy: 0.9425 - val_loss: 2.4628 - val_binary_accuracy: 0.9426\n",
      "Epoch 232/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.4004e-06 - binary_accuracy: 0.9425 - val_loss: 2.4684 - val_binary_accuracy: 0.9426\n",
      "Epoch 233/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.0757e-06 - binary_accuracy: 0.9426 - val_loss: 2.4702 - val_binary_accuracy: 0.9426\n",
      "Epoch 234/1000\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2.2448e-06 - binary_accuracy: 0.9426 - val_loss: 2.4740 - val_binary_accuracy: 0.9426\n",
      "Epoch 235/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.7841e-06 - binary_accuracy: 0.9426 - val_loss: 2.4739 - val_binary_accuracy: 0.9427\n",
      "Epoch 236/1000\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2.2452e-06 - binary_accuracy: 0.9426 - val_loss: 2.4818 - val_binary_accuracy: 0.9427\n",
      "Epoch 237/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.7704e-06 - binary_accuracy: 0.9427 - val_loss: 2.4802 - val_binary_accuracy: 0.9427\n",
      "Epoch 238/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.1002e-06 - binary_accuracy: 0.9427 - val_loss: 2.4895 - val_binary_accuracy: 0.9427\n",
      "Epoch 239/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.1965e-06 - binary_accuracy: 0.9427 - val_loss: 2.4898 - val_binary_accuracy: 0.9427\n",
      "Epoch 240/1000\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.9230e-06 - binary_accuracy: 0.9427 - val_loss: 2.4945 - val_binary_accuracy: 0.9428\n",
      "Epoch 241/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.1247e-06 - binary_accuracy: 0.9427 - val_loss: 2.4955 - val_binary_accuracy: 0.9428\n",
      "Epoch 242/1000\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.5524e-06 - binary_accuracy: 0.9428 - val_loss: 2.4985 - val_binary_accuracy: 0.9428\n",
      "Epoch 243/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.6226e-06 - binary_accuracy: 0.9428 - val_loss: 2.5002 - val_binary_accuracy: 0.9428\n",
      "Epoch 244/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.0356e-06 - binary_accuracy: 0.9428 - val_loss: 2.5064 - val_binary_accuracy: 0.9429\n",
      "Epoch 245/1000\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.6313e-06 - binary_accuracy: 0.9428 - val_loss: 2.5114 - val_binary_accuracy: 0.9429\n",
      "Epoch 246/1000\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.9136e-06 - binary_accuracy: 0.9429 - val_loss: 2.5134 - val_binary_accuracy: 0.9429\n",
      "Epoch 247/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.6414e-06 - binary_accuracy: 0.9429 - val_loss: 2.5170 - val_binary_accuracy: 0.9429\n",
      "Epoch 248/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.6362e-06 - binary_accuracy: 0.9429 - val_loss: 2.5159 - val_binary_accuracy: 0.9429\n",
      "Epoch 249/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.5734e-06 - binary_accuracy: 0.9429 - val_loss: 2.5236 - val_binary_accuracy: 0.9430\n",
      "Epoch 250/1000\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.6632e-06 - binary_accuracy: 0.9429 - val_loss: 2.5275 - val_binary_accuracy: 0.9430\n",
      "Epoch 251/1000\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.2771e-06 - binary_accuracy: 0.9430 - val_loss: 2.5294 - val_binary_accuracy: 0.9430\n",
      "Epoch 252/1000\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.8100e-06 - binary_accuracy: 0.9430 - val_loss: 2.5328 - val_binary_accuracy: 0.9430\n",
      "Epoch 253/1000\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.4011e-06 - binary_accuracy: 0.9430 - val_loss: 2.5377 - val_binary_accuracy: 0.9430\n",
      "Epoch 254/1000\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.5979e-06 - binary_accuracy: 0.9430 - val_loss: 2.5419 - val_binary_accuracy: 0.9431\n",
      "Epoch 255/1000\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.3425e-06 - binary_accuracy: 0.9430 - val_loss: 2.5467 - val_binary_accuracy: 0.9431\n",
      "Epoch 256/1000\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.5162e-06 - binary_accuracy: 0.9431 - val_loss: 2.5492 - val_binary_accuracy: 0.9431\n",
      "Epoch 257/1000\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.4937e-06 - binary_accuracy: 0.9431 - val_loss: 2.5514 - val_binary_accuracy: 0.9431\n",
      "Epoch 258/1000\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.3894e-06 - binary_accuracy: 0.9431 - val_loss: 2.5589 - val_binary_accuracy: 0.9431\n",
      "Epoch 259/1000\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.1714e-06 - binary_accuracy: 0.9431 - val_loss: 2.5594 - val_binary_accuracy: 0.9432\n",
      "Epoch 260/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.4099e-06 - binary_accuracy: 0.9431 - val_loss: 2.5645 - val_binary_accuracy: 0.9432\n",
      "Epoch 261/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.1255e-06 - binary_accuracy: 0.9432 - val_loss: 2.5681 - val_binary_accuracy: 0.9432\n",
      "Epoch 262/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.1476e-06 - binary_accuracy: 0.9432 - val_loss: 2.5743 - val_binary_accuracy: 0.9432\n",
      "Epoch 263/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.0738e-06 - binary_accuracy: 0.9432 - val_loss: 2.5768 - val_binary_accuracy: 0.9432\n",
      "Epoch 264/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.0300e-06 - binary_accuracy: 0.9432 - val_loss: 2.5784 - val_binary_accuracy: 0.9432\n",
      "Epoch 265/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.2730e-06 - binary_accuracy: 0.9432 - val_loss: 2.5838 - val_binary_accuracy: 0.9433\n",
      "Epoch 266/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.0280e-06 - binary_accuracy: 0.9432 - val_loss: 2.5821 - val_binary_accuracy: 0.9433\n",
      "Epoch 267/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.1720e-06 - binary_accuracy: 0.9433 - val_loss: 2.5893 - val_binary_accuracy: 0.9433\n",
      "Epoch 268/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.5138e-06 - binary_accuracy: 0.9433 - val_loss: 2.5958 - val_binary_accuracy: 0.9433\n",
      "Epoch 269/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 9.8393e-07 - binary_accuracy: 0.9433 - val_loss: 2.6015 - val_binary_accuracy: 0.9433\n",
      "Epoch 270/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.1693e-06 - binary_accuracy: 0.9433 - val_loss: 2.5996 - val_binary_accuracy: 0.9434\n",
      "Epoch 271/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 9.1144e-07 - binary_accuracy: 0.9433 - val_loss: 2.6041 - val_binary_accuracy: 0.9434\n",
      "Epoch 272/1000\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 9.9336e-07 - binary_accuracy: 0.9434 - val_loss: 2.6070 - val_binary_accuracy: 0.9434\n",
      "Epoch 273/1000\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.0342e-06 - binary_accuracy: 0.9434 - val_loss: 2.6147 - val_binary_accuracy: 0.9434\n",
      "Epoch 274/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.0491e-06 - binary_accuracy: 0.9434 - val_loss: 2.6205 - val_binary_accuracy: 0.9434\n",
      "Epoch 275/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.1085e-06 - binary_accuracy: 0.9434 - val_loss: 2.6198 - val_binary_accuracy: 0.9434\n",
      "Epoch 276/1000\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.0999e-06 - binary_accuracy: 0.9434 - val_loss: 2.6272 - val_binary_accuracy: 0.9435\n",
      "Epoch 277/1000\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 9.6537e-07 - binary_accuracy: 0.9434 - val_loss: 2.6274 - val_binary_accuracy: 0.9435\n",
      "Epoch 278/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 8.7797e-07 - binary_accuracy: 0.9435 - val_loss: 2.6331 - val_binary_accuracy: 0.9435\n",
      "Epoch 279/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.0442e-06 - binary_accuracy: 0.9435 - val_loss: 2.6377 - val_binary_accuracy: 0.9435\n",
      "Epoch 280/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 8.5481e-07 - binary_accuracy: 0.9435 - val_loss: 2.6478 - val_binary_accuracy: 0.9435\n",
      "Epoch 281/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 8.2612e-07 - binary_accuracy: 0.9435 - val_loss: 2.6464 - val_binary_accuracy: 0.9435\n",
      "Epoch 282/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 8.0977e-07 - binary_accuracy: 0.9435 - val_loss: 2.6463 - val_binary_accuracy: 0.9436\n",
      "Epoch 283/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 8.6117e-07 - binary_accuracy: 0.9435 - val_loss: 2.6523 - val_binary_accuracy: 0.9436\n",
      "Epoch 284/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 8.2596e-07 - binary_accuracy: 0.9436 - val_loss: 2.6571 - val_binary_accuracy: 0.9436\n",
      "Epoch 285/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.3796e-07 - binary_accuracy: 0.9436 - val_loss: 2.6633 - val_binary_accuracy: 0.9436\n",
      "Epoch 286/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.6737e-07 - binary_accuracy: 0.9436 - val_loss: 2.6654 - val_binary_accuracy: 0.9436\n",
      "Epoch 287/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.4588e-07 - binary_accuracy: 0.9436 - val_loss: 2.6693 - val_binary_accuracy: 0.9436\n",
      "Epoch 288/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.2885e-07 - binary_accuracy: 0.9436 - val_loss: 2.6694 - val_binary_accuracy: 0.9436\n",
      "Epoch 289/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.8309e-07 - binary_accuracy: 0.9436 - val_loss: 2.6743 - val_binary_accuracy: 0.9437\n",
      "Epoch 290/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 8.4370e-07 - binary_accuracy: 0.9436 - val_loss: 2.6804 - val_binary_accuracy: 0.9437\n",
      "Epoch 291/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.3014e-07 - binary_accuracy: 0.9437 - val_loss: 2.6869 - val_binary_accuracy: 0.9437\n",
      "Epoch 292/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.2429e-07 - binary_accuracy: 0.9437 - val_loss: 2.6877 - val_binary_accuracy: 0.9437\n",
      "Epoch 293/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.8748e-07 - binary_accuracy: 0.9437 - val_loss: 2.6963 - val_binary_accuracy: 0.9437\n",
      "Epoch 294/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.0693e-07 - binary_accuracy: 0.9437 - val_loss: 2.6965 - val_binary_accuracy: 0.9437\n",
      "Epoch 295/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.4862e-07 - binary_accuracy: 0.9437 - val_loss: 2.6984 - val_binary_accuracy: 0.9438\n",
      "Epoch 296/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.8327e-07 - binary_accuracy: 0.9437 - val_loss: 2.7004 - val_binary_accuracy: 0.9438\n",
      "Epoch 297/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.4768e-07 - binary_accuracy: 0.9438 - val_loss: 2.7078 - val_binary_accuracy: 0.9438\n",
      "Epoch 298/1000\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 6.7778e-07 - binary_accuracy: 0.9438 - val_loss: 2.7160 - val_binary_accuracy: 0.9438\n",
      "Epoch 299/1000\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 6.1461e-07 - binary_accuracy: 0.9438 - val_loss: 2.7158 - val_binary_accuracy: 0.9438\n",
      "Epoch 300/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.3735e-07 - binary_accuracy: 0.9438 - val_loss: 2.7212 - val_binary_accuracy: 0.9438\n",
      "Epoch 301/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.1056e-07 - binary_accuracy: 0.9438 - val_loss: 2.7235 - val_binary_accuracy: 0.9438\n",
      "Epoch 302/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.3641e-07 - binary_accuracy: 0.9438 - val_loss: 2.7272 - val_binary_accuracy: 0.9438\n",
      "Epoch 303/1000\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 5.3060e-07 - binary_accuracy: 0.9438 - val_loss: 2.7308 - val_binary_accuracy: 0.9439\n",
      "Epoch 304/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 5.2220e-07 - binary_accuracy: 0.9438"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-386c0a27f533>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m     h = model.fit(\n\u001b[0m\u001b[0;32m     38\u001b[0m         \u001b[0mpartial_train_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mpartial_train_targets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1187\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1188\u001b[0m                 steps_per_execution=self._steps_per_execution)\n\u001b[1;32m-> 1189\u001b[1;33m           val_logs = self.evaluate(\n\u001b[0m\u001b[0;32m   1190\u001b[0m               \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1191\u001b[0m               \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_test_counter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1457\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m       \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Single epoch.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36menumerate_epochs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1181\u001b[0m     \u001b[1;34m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_truncate_execution_to_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m       \u001b[0mdata_iterator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initial_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    485\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 486\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    487\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m       raise RuntimeError(\"__iter__() is only supported inside of tf.function \"\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[0;32m    694\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcomponents\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0melement_spec\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 696\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    697\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_create_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    717\u001b[0m               \u001b[0moutput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m               output_shapes=self._flat_output_shapes))\n\u001b[1;32m--> 719\u001b[1;33m       \u001b[0mgen_dataset_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mds_variant\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    720\u001b[0m       \u001b[1;31m# Delete the resource when this object is deleted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m       self._resource_deleter = IteratorResourceDeleter(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\u001b[0m in \u001b[0;36mmake_iterator\u001b[1;34m(dataset, iterator, name)\u001b[0m\n\u001b[0;32m   3117\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3118\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3119\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m   3120\u001b[0m         _ctx, \"MakeIterator\", name, dataset, iterator)\n\u001b[0;32m   3121\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Define the number of folds... this will give us an 80/20 split\n",
    "k = 5\n",
    "epochs = 100\n",
    "num_val_samples = len(x_train) // k\n",
    "scores_binacc = []\n",
    "scores_precision = []\n",
    "scores_recall = []\n",
    "histories = []\n",
    "\n",
    "#Train the dense model in k iterations\n",
    "for i in range(k):\n",
    "    print('Processing fold #', i)\n",
    "    val_data = x_train[i * num_val_samples : (i + 1) * num_val_samples]\n",
    "    val_targets = y_train[i * num_val_samples : (i + 1) * num_val_samples]\n",
    "    \n",
    "    print('Validation partition =  ', i * num_val_samples, (i + 1) * num_val_samples)\n",
    "    print('Training partition 1 = ', 0, i * num_val_samples)\n",
    "    print('Training partition 2 = ', (i+1) * num_val_samples, len(x_train))\n",
    "    \n",
    "    partial_train_data = np.concatenate(\n",
    "        [\n",
    "            x_train[:i * num_val_samples],\n",
    "            x_train[(i+1) * num_val_samples:]\n",
    "        ], \n",
    "        axis=0\n",
    "    )\n",
    "    \n",
    "    partial_train_targets = np.concatenate(\n",
    "        [\n",
    "            y_train[:i * num_val_samples],\n",
    "            y_train[(i+1) * num_val_samples:]\n",
    "        ],\n",
    "        axis=0\n",
    "    )\n",
    "    \n",
    "    model = build_model()\n",
    "    h = model.fit(\n",
    "        partial_train_data, \n",
    "        partial_train_targets, \n",
    "        validation_data=(val_data, val_targets),\n",
    "        epochs=epochs, \n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    val_loss, val_binacc, val_precision, val_recall = model.evaluate(val_data, val_targets, verbose=0)\n",
    "    scores_binacc.append(val_binacc)\n",
    "    scores_precision.append(val_precision)\n",
    "    scores_recall.append(val_recall)\n",
    "    histories.append(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Validation Binary Accuracy:  0.7430366396903991\n",
      "Mean Validation Precision:  nan\n",
      "Mean Validation Recall:  nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nkho_\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\nkho_\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0.]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shapes (1, 50, 10, 1) and (1, 50) are incompatible",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-d614278f8253>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;33m[\u001b[0m\u001b[0mx_test_predictions\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m )\n\u001b[1;32m---> 17\u001b[1;33m p.update_state(\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[1;33m[\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;33m[\u001b[0m\u001b[0mx_test_predictions\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\metrics_utils.py\u001b[0m in \u001b[0;36mdecorated\u001b[1;34m(metric_obj, *args, **kwargs)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_context_for_symbolic_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m       \u001b[0mupdate_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_state_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mupdate_op\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# update_op will be None in eager execution.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m       \u001b[0mmetric_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mupdate_op\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\metrics.py\u001b[0m in \u001b[0;36mupdate_state_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    175\u001b[0m         \u001b[0mcontrol_status\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m         \u001b[0mag_update_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj_update_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontrol_status\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mag_update_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    178\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdef_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFunction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    690\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    691\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 692\u001b[1;33m           \u001b[1;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    693\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    694\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ag_error_metadata'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    334\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_in_allowlist_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Allowlisted %s: from cache'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 336\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    462\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 463\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    464\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\metrics.py\u001b[0m in \u001b[0;36mupdate_state\u001b[1;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[0;32m   1325\u001b[0m       \u001b[0mUpdate\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \"\"\"\n\u001b[1;32m-> 1327\u001b[1;33m     return metrics_utils.update_confusion_matrix_variables(\n\u001b[0m\u001b[0;32m   1328\u001b[0m         {\n\u001b[0;32m   1329\u001b[0m             \u001b[0mmetrics_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConfusionMatrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRUE_POSITIVES\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrue_positives\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\metrics_utils.py\u001b[0m in \u001b[0;36mupdate_confusion_matrix_variables\u001b[1;34m(variables_to_update, y_true, y_pred, thresholds, top_k, class_id, sample_weight, multi_label, label_weights)\u001b[0m\n\u001b[0;32m    364\u001b[0m           losses_utils.squeeze_or_expand_dimensions(\n\u001b[0;32m    365\u001b[0m               y_pred, y_true, sample_weight=sample_weight))\n\u001b[1;32m--> 366\u001b[1;33m   \u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_is_compatible_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    367\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtop_k\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\u001b[0m in \u001b[0;36massert_is_compatible_with\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m   1159\u001b[0m     \"\"\"\n\u001b[0;32m   1160\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1161\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Shapes %s and %s are incompatible\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1163\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mmost_specific_compatible_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Shapes (1, 50, 10, 1) and (1, 50) are incompatible"
     ]
    }
   ],
   "source": [
    "print('Mean Validation Binary Accuracy: ', np.mean(scores_binacc))\n",
    "print('Mean Validation Precision: ', np.mean(scores_precision))\n",
    "print('Mean Validation Recall: ', np.mean(scores_recall))\n",
    "\n",
    "x_test_predictions = model.predict(np.array(x_test))\n",
    "\n",
    "b = keras.metrics.BinaryAccuracy()\n",
    "p = keras.metrics.Precision() \n",
    "r = keras.metrics.Recall()\n",
    "\n",
    "print(y_test)\n",
    "\n",
    "b.update_state(\n",
    "    [y_test],\n",
    "    [x_test_predictions]\n",
    ")\n",
    "p.update_state(\n",
    "    [y_test],\n",
    "    [x_test_predictions]\n",
    ")\n",
    "r.update_state(\n",
    "    [y_test],\n",
    "    [x_test_predictions]\n",
    ")\n",
    "\n",
    "print('Test Binary Accuracy: ', b.result().numpy())\n",
    "print('Test Precision: ', p.result().numpy())\n",
    "print('Test Recall: ', r.result().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLOTS\n",
    "plt.figure(figsize=(25, 5))\n",
    "\n",
    "\n",
    "\n",
    "e = range(1, epochs + 1)\n",
    "    \n",
    "for i, h in enumerate(histories):\n",
    "    plt.subplot(131)\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.plot(e, histories[i].history['loss'], 'r-', label='Training Fold ' + str(i))\n",
    "    plt.plot(e, histories[i].history['val_loss'], 'g-', label='Validation Fold ' + str(i))\n",
    "    \n",
    "    plt.subplot(132)\n",
    "    plt.title('Training and validation binary accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Binary Accuracy')\n",
    "    plt.plot(e, histories[i].history['binary_accuracy'], 'r-', label='Training Fold ' + str(i))\n",
    "    plt.plot(e, histories[i].history['val_binary_accuracy'], 'g-', label='Validation Fold ' + str(i))\n",
    "    \n",
    "    \n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(cmodel.predict(x_train_seqs), bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
